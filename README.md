# ollama-colab-gpu
LLMs on Colab using Ollama (No Local GPU Needed!)
